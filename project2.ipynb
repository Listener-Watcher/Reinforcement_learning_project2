{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "933d2925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QL\n",
      "---------\n",
      "→ → → → → → → G \n",
      "→ → → → → → ↑ ↑ \n",
      "↑ → ↑ ↑ ↑ → ↑ ↑ \n",
      "→ → → ↑ ↑ ↑ ↑ ↑ \n",
      "↑ → → ↑ ↑ ↑ ↑ ↑ \n",
      "↑ → → ↑ ↑ ↑ ↑ ↑ \n",
      "↑ ↑ → → ↑ ↑ ↑ ↑ \n",
      "→ ↑ ↑ ↑ → ↑ ↑ ↑ \n",
      "MC\n",
      "---------\n",
      "→ → → → → → → G \n",
      "↑ → → → → → → ↑ \n",
      "↑ → → → ↑ ↑ ↑ ↑ \n",
      "→ ↑ → → → ↑ ↑ ↑ \n",
      "↑ ↑ → → → ↑ ↑ ↑ \n",
      "→ ↑ ↑ → ↑ → ↑ ↑ \n",
      "↑ → → ↑ ↑ ↑ ↑ ↑ \n",
      "→ → ↑ ↑ → → → ↑ \n",
      "Sarsa\n",
      "---------\n",
      "→ → → → → → → G \n",
      "→ → → ↑ ↑ → ↑ ↑ \n",
      "→ → → ↑ ↑ → ↑ ↑ \n",
      "→ ↑ ↑ ↑ → → → ↑ \n",
      "↑ → ↑ ↑ → → ↑ ↑ \n",
      "↑ → → → ↑ ↑ ↑ ↑ \n",
      "→ → ↑ → ↑ ↑ → ↑ \n",
      "→ ↑ ↑ → → → ↑ ↑ \n",
      "end\n",
      "DQL\n",
      "→ → → → → → → G \n",
      "→ → → → → → ↑ ↑ \n",
      "→ → → ↑ ↑ → ↑ ↑ \n",
      "→ ↑ → → ↑ ↑ ↑ ↑ \n",
      "→ ↑ → → → ↑ ↑ ↑ \n",
      "→ ↑ → → → ↑ ↑ ↑ \n",
      "→ → → ↑ ↑ ↑ ↑ ↑ \n",
      "→ ↑ ↑ ↑ ↑ ↑ ↑ ↑ \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22f3fb7cd90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x194.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x194.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "class GridWorld():\n",
    "    def __init__(self,rewards,states,agent):\n",
    "        self.r = rewards # reward for each grid\n",
    "        self.statespace = states\n",
    "        self.agent = agent\n",
    "    def action_map(self,action,cur):\n",
    "        # 1 is N\n",
    "        future = [cur[0],cur[1]]\n",
    "        if action==0:\n",
    "            future[0] = future[0]-1\n",
    "        # 2 is E\n",
    "        elif action==1:\n",
    "            future[1] = future[1]+1\n",
    "        # 3 is S\n",
    "        elif action==2:\n",
    "            future[0] = future[0]+1\n",
    "        # 4 is W\n",
    "        else:\n",
    "            future[1] = future[1]-1\n",
    "        return future\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self,cur_pos,states,actions):\n",
    "        self.pos = cur_pos\n",
    "        self.action_space = actions\n",
    "        self.state_space = states\n",
    "        self.V = np.zeros((states))\n",
    "        self.Q = np.zeros((states,actions))\n",
    "    def make_action(self):\n",
    "        action = random.randint(0,self.action_space)\n",
    "        return action\n",
    "    \n",
    "\n",
    "class Controller():\n",
    "    def __init__(self,start_pos,row,col,actions,reward,T):\n",
    "        self.row = row\n",
    "        self.col = col\n",
    "        self.T = T\n",
    "        self.action_space = actions\n",
    "        self.agent = Agent(start_pos,row*col,actions)\n",
    "        self.gridworld = GridWorld(reward,row*col,self.agent)\n",
    "        self.V = np.zeros((self.row*self.col))\n",
    "        self.Q = np.zeros((self.row*self.col,actions))\n",
    "#         for state in range(self.row*self.col):\n",
    "#             for action in range(0,self.action_space):\n",
    "#                 if not self.has_position(self.gridworld.action_map(action,self.convert_back(state))):\n",
    "#                     self.Q[state,action] = -1000000\n",
    "        self.epsilon = 0.001\n",
    "        self.history = []\n",
    "    def convert(self,state):\n",
    "        return state[0]*self.col+state[1]\n",
    "    def convert_back(self,index):\n",
    "        return [index//self.col,index-((index)//self.col*self.col)]\n",
    "    def has_position(self,state):\n",
    "        if state[0]<0 or state[0]>=self.row or state[1]<0 or state[1]>=self.col:\n",
    "#             print(\"state\",state)\n",
    "#             print(\"self.row\",self.row)\n",
    "#             print(\"self.col\",self.col)\n",
    "#             print(\"illegal move!\")\n",
    "            return False\n",
    "        elif self.T[state[0],state[1]]==1:\n",
    "#             print(\"Terminal\",self.T[state[0],state[1]])\n",
    "#             print('hit wall')\n",
    "            return False\n",
    "        else:\n",
    "#             print(\"Terminal\",self.T[state[0],state[1]])\n",
    "            return True\n",
    "    def find_max(self,state,Q):\n",
    "        index = self.convert(state)\n",
    "        available_action = []\n",
    "        available_value = []\n",
    "        for a in range(self.action_space):\n",
    "            if self.has_position(self.gridworld.action_map(a,self.convert_back(index))):\n",
    "                available_action.append(a)\n",
    "                available_value.append(Q[index,a])\n",
    "        max_value = np.max(np.array(available_value))\n",
    "        return max_value\n",
    "    def find_argmax(self,state,Q):\n",
    "        index = self.convert(state)\n",
    "        available_action = []\n",
    "        available_value = []\n",
    "        for a in range(self.action_space):\n",
    "            if self.has_position(self.gridworld.action_map(a,self.convert_back(index))):\n",
    "                available_action.append(a)\n",
    "                available_value.append(Q[index,a])\n",
    "        action_index = np.argmax(np.array(available_value))\n",
    "        action = available_action[action_index]\n",
    "        return action\n",
    "    def allmax(self,a):\n",
    "        if len(a) == 0:\n",
    "            return []\n",
    "        all_ = [0]\n",
    "        max_ = a[0]\n",
    "        for i in range(1, len(a)):\n",
    "            if a[i] > max_:\n",
    "                all_ = [i]\n",
    "                max_ = a[i]\n",
    "            elif a[i] == max_:\n",
    "                all_.append(i)\n",
    "        return all_\n",
    "    def action_policy(self,index,t):\n",
    "        index = self.convert(index)\n",
    "#         print(\"enter action_policy function\",self.convert_back(index))\n",
    "        epi = random.randint(0,1)\n",
    "        if epi<(self.epsilon/t):\n",
    "#             print(\"random case\")\n",
    "            available_action = []\n",
    "            available_value = []\n",
    "            for a in range(self.action_space):\n",
    "                if self.has_position(self.gridworld.action_map(a,self.convert_back(index))):\n",
    "                    available_action.append(a)\n",
    "            action_index = random.randint(0,len(available_action)-1)\n",
    "            action = available_action[action_index]\n",
    "        else:\n",
    "            available_action = []\n",
    "            available_value = []\n",
    "            for a in range(self.action_space):\n",
    "                if self.has_position(self.gridworld.action_map(a,self.convert_back(index))):\n",
    "                    available_action.append(a)\n",
    "                    available_value.append(self.Q[index,a])\n",
    "            actions = self.allmax((available_value))\n",
    "            a2 = random.randint(0,len(actions)-1)\n",
    "            action_index = actions[a2]\n",
    "            action = available_action[action_index]\n",
    "        return action\n",
    "    def action_policy_doubleQ(self,index,t,Q2):\n",
    "        index = self.convert(index)\n",
    "        epi = random.randint(0,1)\n",
    "        if epi<(self.epsilon/t):\n",
    "            action = random.randint(0,self.action_space-1)\n",
    "            while not self.has_position(self.gridworld.action_map(action,self.convert_back(index))):\n",
    "                action = random.randint(0,self.action_space-1)\n",
    "        else:\n",
    "            actions = self.allmax(self.Q[index]+Q2[index])\n",
    "            a2 = random.randint(0,len(actions)-1)\n",
    "            action = actions[a2]\n",
    "#             action = np.argmax(self.Q[index])\n",
    "        return action\n",
    "    def render_action(self,action):\n",
    "        display = ''\n",
    "        if action==0:\n",
    "            display='\\u2191'\n",
    "        elif action==1:\n",
    "            display='\\u2192'\n",
    "        elif action==2:\n",
    "            display='\\u2193'\n",
    "        else:\n",
    "            display='\\u2190'\n",
    "        return display\n",
    "    def render(self):\n",
    "#         for i in range(self.row):\n",
    "#             for j in range(self.col):\n",
    "#                 print(np.max(self.Q[i*self.col+j]),end=' ')\n",
    "#             print()\n",
    "        print(\"---------\")\n",
    "        for i in range(self.row):\n",
    "            for j in range(self.col):\n",
    "                if self.T[i,j]==2:\n",
    "                    print(\"G\",end=' ')\n",
    "                elif self.T[i,j]==1:\n",
    "                    print(\"X\",end=' ')\n",
    "                else:\n",
    "                    available_action = []\n",
    "                    available_value = []\n",
    "                    for a in range(self.action_space):\n",
    "                        if self.has_position(self.gridworld.action_map(a,self.convert_back(i*self.col+j))):\n",
    "                            available_action.append(a)\n",
    "                            available_value.append(self.Q[i*self.col+j,a])\n",
    "                    actions = self.allmax(available_value)\n",
    "                    a2 = random.randint(0,len(actions)-1)\n",
    "                    action_index = actions[a2]\n",
    "                    action = available_action[action_index]\n",
    "                    print(self.render_action(action),end=' ')\n",
    "            print()\n",
    "    def render_DP(self):\n",
    "        for i in range(self.row):\n",
    "            for j in range(self.col):\n",
    "                if self.T[i,j]==2:\n",
    "                    print(\"G\",end=' ')\n",
    "                elif self.T[i,j]==1:\n",
    "                    print(\"X\",end=' ')\n",
    "                else:\n",
    "                    Update_value = []\n",
    "                    for a in range(self.action_space):\n",
    "                        future = self.gridworld.action_map(a,[i,j])\n",
    "                        if not self.has_position(future):\n",
    "                            future = [i,j]\n",
    "                            reward = -100000\n",
    "                        else:\n",
    "                            reward = self.gridworld.r[future[0],future[1]]\n",
    "                        Update_value.append(reward+0.01*self.V[self.convert(future)])\n",
    "                    max_action = np.argmax(np.array(Update_value))\n",
    "                    print(self.render_action(max_action),end=' ')\n",
    "            print()\n",
    "        print(self.V)\n",
    "            \n",
    "    def render_DQ(self,Q):\n",
    "#         print(\"V table for DQ\")\n",
    "#         for i in range(self.row):\n",
    "#             for j in range(self.col):\n",
    "#                 print(np.max((self.Q[i*self.col+j]+Q[i*self.col+j])/2),end=' ')\n",
    "#             print()\n",
    "#         print(\"---------\")\n",
    "        for i in range(self.row):\n",
    "            for j in range(self.col):\n",
    "                if self.T[i,j]==2:\n",
    "                    print(\"G\",end=' ')\n",
    "                elif self.T[i,j]==1:\n",
    "                    print(\"X\",end=' ')\n",
    "                else:\n",
    "                    available_action = []\n",
    "                    available_value = []\n",
    "                    for a in range(self.action_space):\n",
    "                        if self.has_position(self.gridworld.action_map(a,self.convert_back(i*self.col+j))):\n",
    "                            available_action.append(a)\n",
    "                            available_value.append(self.Q[i*self.col+j,a]+Q[i*self.col+j,a])\n",
    "                    actions = self.allmax(available_value)\n",
    "                    a2 = random.randint(0,len(actions)-1)\n",
    "                    action_index = actions[a2]\n",
    "                    action = available_action[action_index]\n",
    "                    print(self.render_action(action),end=' ')\n",
    "#                     print(self.render_action(np.argmax(self.Q[i*self.col+j]+Q[i*self.col+j])),end=' ')\n",
    "            print()\n",
    "    def reset(self):\n",
    "        self.V = np.zeros((self.row*self.col))\n",
    "        self.Q = np.zeros((self.row*self.col,self.action_space))\n",
    "        self.epsilon = 0.001\n",
    "        self.history = []\n",
    "    def eval_mode(self,V):\n",
    "        self.V = V\n",
    "        print(\"---------\")\n",
    "        for i in range(self.row):\n",
    "            for j in range(self.col):\n",
    "                if self.T[i,j]==2:\n",
    "                    print(\"G\",end=' ')\n",
    "                elif self.T[i,j]==1:\n",
    "                    print(\"X\",end=' ')\n",
    "                else:\n",
    "                    available_action = []\n",
    "                    available_value = []\n",
    "                    for a in range(self.action_space):\n",
    "                        if self.has_position(self.gridworld.action_map(a,self.convert_back(i*self.col+j))):\n",
    "                            available_action.append(a)\n",
    "                            future = self.gridworld.action_map(a,[i,j])\n",
    "                            reward = self.gridworld.r[future[0],future[1]]\n",
    "                            available_value.append(reward+0.01*self.V[self.convert(future)])\n",
    "                    max_action = np.argmax(np.array(available_value))\n",
    "                    max_action = available_action[max_action]\n",
    "                    print(self.render_action(max_action),end=' ')\n",
    "            print()\n",
    "    def generate_epsiode(self):\n",
    "        epsiode = []\n",
    "#         start = [0,0]\n",
    "        Reward = []\n",
    "        step = 0\n",
    "        states = []\n",
    "        row_s = random.randint(0,self.row-1)\n",
    "        col_s = random.randint(0,self.col-1)\n",
    "        start = [row_s,col_s]\n",
    "        while(self.T[row_s,col_s]!=0):\n",
    "            row_s = random.randint(0,self.row-1)\n",
    "            col_s = random.randint(0,self.col-1)\n",
    "            start = [row_s,col_s]\n",
    "        while self.T[start[0],start[1]] !=2:\n",
    "            action = self.action_policy(start,1)\n",
    "            future = self.gridworld.action_map(action,start)\n",
    "            reward = self.gridworld.r[future[0],future[1]]\n",
    "            epsiode.append((self.convert(start),action,reward))\n",
    "            states.append((self.convert(start),action))\n",
    "            start = future\n",
    "            step = step+1\n",
    "        return epsiode,states,step\n",
    "    def start(self,mode):\n",
    "        alpha = 0.5\n",
    "        gamma = 0.01\n",
    "#         row_s = random.randint(0,self.row-1)\n",
    "#         col_s = random.randint(0,self.col-1)\n",
    "        start = [0,0]\n",
    "        Reward = []\n",
    "        V_step = []\n",
    "        Q2 = self.Q\n",
    "        if mode == 'QL': # off policy TD\n",
    "            iteration=0\n",
    "            step = 0\n",
    "            while iteration<=10000:\n",
    "                while self.T[start[0],start[1]] ==2:\n",
    "                    #print(\"epsiode over, start again\")\n",
    "                    row_s = random.randint(0,self.row-1)\n",
    "                    col_s = random.randint(0,self.col-1)\n",
    "                    start = [row_s,col_s]\n",
    "                    Reward.append(step)\n",
    "                    step = 0\n",
    "                    V_step.append(np.max(self.Q,axis=1))\n",
    "#                 print(\"select action\")\n",
    "#                 print(\"state\",start)\n",
    "                action = self.action_policy(start,1)\n",
    "#                 print(\"action:\",self.render_action(action))\n",
    "                future = self.gridworld.action_map(action,start)\n",
    "                reward = self.gridworld.r[future[0],future[1]]\n",
    "                self.Q[self.convert(start),action] = (1-alpha)*self.Q[self.convert(start),action]+alpha*(reward+gamma*self.find_max(future,self.Q))\n",
    "                start = future\n",
    "                iteration+=1\n",
    "                step+=1\n",
    "            self.render()\n",
    "        elif mode == 'Sarsa': #on policy TD\n",
    "            iteration=0\n",
    "#             row_s = random.randint(0,self.row-1)\n",
    "#             col_s = random.randint(0,self.col-1)\n",
    "            start = [0,0]\n",
    "            step = 0\n",
    "#             while self.T[start[0],start[1]] !=0:\n",
    "#                 row_s = random.randint(0,self.row-1)\n",
    "#                 col_s = random.randint(0,self.col-1)\n",
    "            action = self.action_policy(start,1)\n",
    "            while iteration<=10000:\n",
    "                while self.T[start[0],start[1]] ==2:\n",
    "                    #epsiode over, start again\n",
    "                    row_s = random.randint(0,self.row-1)\n",
    "                    col_s = random.randint(0,self.col-1)\n",
    "                    start = [row_s,col_s]\n",
    "                    action = self.action_policy(start,1)\n",
    "                    Reward.append(step)\n",
    "                    V_step.append(np.max(self.Q,axis=1))\n",
    "                    step = 0\n",
    "                future = self.gridworld.action_map(action,start)\n",
    "                reward = self.gridworld.r[future[0],future[1]]\n",
    "                action_future = self.action_policy(future,1)\n",
    "#                 print(\"current state:\",start)\n",
    "#                 print(\"current action:\",self.render_action(action))\n",
    "#                 print(\"future state:\",future)\n",
    "#                 print(\"future action selected\",self.render_action(action_future))\n",
    "                self.Q[self.convert(start),action] = (1-alpha)*self.Q[self.convert(start),action]+alpha*(reward+gamma*self.Q[self.convert(future),action_future])\n",
    "                start = future\n",
    "                action = action_future\n",
    "                step +=1\n",
    "                iteration+=1\n",
    "            self.render()\n",
    "            print(\"end\")\n",
    "        elif mode == 'DQL': # double Q\n",
    "            iteration=0\n",
    "            step = 0\n",
    "            while iteration<=8000:\n",
    "                if iteration>=7900:\n",
    "                    self.epsilon = 0\n",
    "                while self.T[start[0],start[1]] ==2:\n",
    "                    #print(\"epsiode over, start again\")\n",
    "                    row_s = random.randint(0,self.row-1)\n",
    "                    col_s = random.randint(0,self.col-1)\n",
    "                    start = [row_s,col_s]\n",
    "                    Reward.append(step)\n",
    "                    V_step.append(np.max(((self.Q+Q2)/2),axis=1))\n",
    "                    step = 0\n",
    "                action = self.action_policy(start,1)\n",
    "                future = self.gridworld.action_map(action,start)\n",
    "                reward = self.gridworld.r[future[0],future[1]]\n",
    "                dq = random.randint(0,1)\n",
    "                if dq<=0.5:\n",
    "                    self.Q[self.convert(start),action] = (1-alpha)*self.Q[self.convert(start),action]+alpha*(reward+gamma*Q2[self.convert(future),self.find_argmax(future,self.Q)])\n",
    "                else:\n",
    "                    Q2[self.convert(start),action] = (1-alpha)*Q2[self.convert(start),action]+alpha*(reward+gamma*self.Q[self.convert(future),self.find_argmax(future,Q2)])\n",
    "                start = future\n",
    "                iteration+=1\n",
    "                step+=1\n",
    "            self.render_DQ(Q2)\n",
    "        elif mode == 'MC': # first visit MC value estimation\n",
    "            iteration = 0\n",
    "            Returns = [[[]for j in range(self.action_space)] for i in range(self.row*self.col)]\n",
    "            while iteration<=6000:\n",
    "                epsiode,state_action_pairs,steps = self.generate_epsiode()\n",
    "                G = 0\n",
    "                for i in range(len(epsiode)-1,-1,-1):\n",
    "                    G = gamma*G+epsiode[i][2]\n",
    "                    temp_states = state_action_pairs[i-1::-1]\n",
    "                    if state_action_pairs[i] in temp_states:\n",
    "                        pass\n",
    "                    else:\n",
    "                        Returns[state_action_pairs[i][0]][state_action_pairs[i][1]].append(G)\n",
    "                        self.Q[state_action_pairs[i][0],state_action_pairs[i][1]] = sum(Returns[state_action_pairs[i][0]][state_action_pairs[i][1]])/len(Returns[state_action_pairs[i][0]][state_action_pairs[i][1]])\n",
    "                Reward.append(steps)\n",
    "                V_step.append(np.max(self.Q,axis=1))\n",
    "                iteration+=1\n",
    "            self.render()\n",
    "        elif mode == 'DP':\n",
    "            gamma = 0.1\n",
    "            iteration=0\n",
    "            while True:\n",
    "                delta = 0\n",
    "                for i in range(self.row):\n",
    "                    for j in range(self.col):\n",
    "                        if self.T[i,j]==0:\n",
    "                            v = self.V[self.convert([i,j])]\n",
    "                            Update_value = []\n",
    "                            for a in range(self.action_space):\n",
    "                                future = self.gridworld.action_map(a,[i,j])\n",
    "                                if not self.has_position(future):\n",
    "                                    future = [i,j]\n",
    "                                    reward = -100\n",
    "                                else:\n",
    "                                    reward = self.gridworld.r[future[0],future[1]]\n",
    "                                Update_value.append(reward+gamma*self.V[self.convert(future)])\n",
    "                            max_update = max(Update_value)\n",
    "                            self.V[self.convert([i,j])] = max_update\n",
    "                            delta = max([delta,abs(v-self.V[self.convert([i,j])])])\n",
    "                        else:\n",
    "                            pass\n",
    "                V_step.append(self.V)\n",
    "                Reward.append(iteration)\n",
    "                iteration +=1\n",
    "                if delta<0.00000001:\n",
    "                    break\n",
    "            self.render_DP()\n",
    "        else:\n",
    "            pass\n",
    "        return Reward,V_step\n",
    "        \n",
    "\n",
    "#     R = np.array([[0,-80,100],[0,0,0],[25,-100,80]])\n",
    "#     Terminal = np.array([[0,2,2],[0,0,0],[2,2,2]])\n",
    "# R = np.array([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,100],[0,0,0,0,0],[0,0,0,0,0]])\n",
    "# Terminal = np.array([[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,2],[0,0,0,0,0],[0,0,0,0,0]])\n",
    "# R = np.array([[0,0,0,0,0,0,0,100],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0]])\n",
    "# Terminal = np.array([[0,0,1,0,1,1,1,2],[0,0,1,0,0,0,0,0],[0,0,0,0,1,1,1,0],[0,0,0,0,0,0,0,0],[0,0,1,0,1,0,1,0],[1,1,0,0,0,0,0,0],[0,0,0,0,0,0,1,0],[0,0,0,0,0,0,1,0]])\n",
    "R = np.array([[0,0,0,0,0,0,0,100],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0]])\n",
    "Terminal = np.array([[0,0,0,0,0,0,0,2],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0]])\n",
    "start = [0,0]\n",
    "actions = 4\n",
    "controller = Controller(start,R.shape[0],R.shape[1],actions,R,Terminal)\n",
    "print(\"QL\")\n",
    "Reward_QL,V_QL = controller.start(\"QL\")\n",
    "V_optimal = np.max(controller.Q,axis=1)\n",
    "# print(V_optimal)\n",
    "# #     print(\"theoretical value table K\",np.max(controller.Q,axis=1))\n",
    "controller.reset()\n",
    "print(\"MC\")\n",
    "Reward_MC,V_MC = controller.start(\"MC\")\n",
    "controller.reset()\n",
    "print(\"Sarsa\")\n",
    "Reward_SARSA,V_SARSA = controller.start(\"Sarsa\")\n",
    "controller.reset()\n",
    "print(\"DQL\")\n",
    "Reward_DQL,V_DQL= controller.start(\"DQL\")\n",
    "# #     V_optimal = np.max(controller.Q,axis=1)\n",
    "#     print(\"DP\")\n",
    "#     controller.reset()\n",
    "#     Reward_DP,V_DP = controller.start(\"DP\")\n",
    "RMSE_QL = []\n",
    "RMSE_DQL = []\n",
    "RMSE_SARSA = []\n",
    "RMSE_DP = []\n",
    "RMSE_MC = []\n",
    "for x in V_QL:\n",
    "    RMSE_QL.append(np.sqrt(np.mean((x-V_optimal)**2)))\n",
    "for x in V_DQL:\n",
    "    RMSE_DQL.append(np.sqrt(np.mean((x-V_optimal)**2)))\n",
    "    for x in V_SARSA:\n",
    "        RMSE_SARSA.append(np.sqrt(np.mean((x-V_optimal)**2)))\n",
    "#     for x in V_DP:\n",
    "#         RMSE_DP.append(np.sqrt(np.mean((x-V_optimal)**2)))\n",
    "for x in V_MC:\n",
    "    RMSE_MC.append(np.sqrt(np.mean((x-V_optimal)**2)))\n",
    "#     x1 = []\n",
    "#     for i in range(len(Reward_DQL)):\n",
    "#         x1.append(i+1)\n",
    "x2 = []\n",
    "for i in range(len(Reward_QL)):\n",
    "    x2.append(i+1)\n",
    "dql = []\n",
    "for i in range(len(Reward_DQL)):\n",
    "    dql.append(i+1)\n",
    "sarsa = []\n",
    "for i in range(len(Reward_SARSA)):\n",
    "    sarsa.append(i+1)\n",
    "#     x4 = []\n",
    "#     for i in range(len(Reward_DP)):\n",
    "#         x4.append(i+1)\n",
    "mc = []\n",
    "for i in range(len(Reward_MC)):\n",
    "    mc.append(i+1)\n",
    "fig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained')\n",
    "#     ax.plot(x1[0:80:1],Reward_DQL[0:80:1], label='DQL')\n",
    "ax.plot(x2[0:40:1],Reward_QL[0:40:1],label='QL')\n",
    "ax.plot(dql[0:40:1],Reward_DQL[0:40:1],label='DQL')\n",
    "ax.plot(sarsa[0:40:1],Reward_SARSA[0:40:1],label='SARSA')\n",
    "ax.plot(mc[0:40:1],Reward_MC[0:40:1],label='MC')\n",
    "ax.set_xlabel('epsiodes')  # Add an x-label to the axes.\n",
    "ax.set_ylabel('number of steps towards goal')  # Add a y-label to the axes.\n",
    "ax.set_title(\"Step-to-go curve\")  # Add a title to the axes.\n",
    "ax.legend()  # Add a legend.\n",
    "fig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained')\n",
    "ax.plot(x2[0:20:1],RMSE_QL[0:20:1],label='QL')\n",
    "ax.plot(sarsa[0:20:1],RMSE_SARSA[0:20:1],label='SARSA')\n",
    "#     ax.plot(x4,RMSE_DP,label='DP')\n",
    "ax.plot(mc[0:20:1],RMSE_MC[0:20:1], label='MC')\n",
    "ax.plot(dql[0:20:1],RMSE_DQL[0:20:1], label='DQL')\n",
    "ax.set_xlabel('epsiodes')  # Add an x-label to the axes.\n",
    "ax.set_ylabel('RMS error')  # Add a y-label to the axes.\n",
    "#     ax.set_title(\"Plot for MC\")  # Add a title to the axes.\n",
    "ax.legend()  # Add a legend.\n",
    "\n",
    "#     fig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained')\n",
    "#     ax.plot(x2[0:80:1],RMSE_QL[0:80:1],label='QL')\n",
    "\n",
    "#     ax.set_xlabel('epsiodes')  # Add an x-label to the axes.\n",
    "#     ax.set_ylabel('RMS error')  # Add a y-label to the axes.\n",
    "#     ax.set_title(\"Plot for QL\")  # Add a title to the axes.\n",
    "#     ax.legend()  # Add a legend.\n",
    "#     fig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained')\n",
    "#     ax.plot(x3[0:80:1],RMSE_SARSA[0:80:1],label='SARSA')\n",
    "\n",
    "#     ax.set_xlabel('epsiodes')  # Add an x-label to the axes.\n",
    "#     ax.set_ylabel('RMS error')  # Add a y-label to the axes.\n",
    "#     ax.set_title(\"Plot for SARSA\")  # Add a title to the axes.\n",
    "#     ax.legend()  # Add a legend.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee21d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim,num_layers):\n",
    "        super(ANN, self).__init__()\n",
    "        self.activations = nn.ModuleList()\n",
    "        self.activations.append(nn.ReLU(hid_dim))\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(in_dim,hid_dim))\n",
    "#         self.dropouts = nn.ModuleList()\n",
    "#         self.dropouts.append(nn.Dropout(p=0.5))\n",
    "        self.num_layers = num_layers\n",
    "        for _ in range(self.num_layers):\n",
    "            self.layers.append(nn.Linear(hid_dim,hid_dim))\n",
    "            self.activations.append(nn.ReLU(hid_dim))\n",
    "#             self.dropouts.append(nn.Dropout(p=0.5))\n",
    "        self.layers.append(nn.Linear(hid_dim,out_dim))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        for fnn, act in zip(self.layers,self.activations):\n",
    "            x = fnn(x)\n",
    "            x = act(x)\n",
    "#             z = drop(z)\n",
    "        out = self.layers[-1](x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf377b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30. 38. 45. 54. 56. 60. 63.  0. 22. 34. 41. 46. 51. 55. 59. 62. 18. 27.\n",
      " 35. 42. 48. 52. 57. 61. 14. 21. 28. 33. 39. 47. 50. 58.  9. 15. 20. 24.\n",
      " 31. 40. 49. 53.  6. 10. 13. 17. 25. 36. 43. 44.  3.  5.  7. 11. 16. 23.\n",
      " 32. 37.  1.  2.  4.  8. 12. 19. 26. 29.]\n",
      "# params: 745\n",
      "X [[1 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17518\\anaconda3\\envs\\AGCL_ENV\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 1332.5920958105396\n",
      "epoch 0\n",
      "training loss 1321.37967272379\n",
      "epoch 1\n",
      "training loss 1279.4888198603635\n",
      "epoch 2\n",
      "training loss 1137.3380787448748\n",
      "epoch 3\n",
      "training loss 800.0320522131606\n",
      "epoch 4\n",
      "training loss 448.3424885896306\n",
      "epoch 5\n",
      "training loss 324.5982610251646\n",
      "epoch 6\n",
      "training loss 304.5933959912814\n",
      "epoch 7\n",
      "training loss 290.0753529976612\n",
      "epoch 8\n",
      "training loss 277.95041211374433\n",
      "epoch 9\n",
      "training loss 262.98986380296196\n",
      "epoch 10\n",
      "training loss 252.50013547516198\n",
      "epoch 11\n",
      "training loss 239.98732948066478\n",
      "epoch 12\n",
      "training loss 227.7944194228582\n",
      "epoch 13\n",
      "training loss 216.51062638056\n",
      "epoch 14\n",
      "training loss 206.34696854590308\n",
      "epoch 15\n",
      "training loss 194.60681386271787\n",
      "epoch 16\n",
      "training loss 183.38989805590677\n",
      "epoch 17\n",
      "training loss 172.44809842318435\n",
      "epoch 18\n",
      "training loss 161.08937554011604\n",
      "epoch 19\n",
      "training loss 151.1626022057357\n",
      "epoch 20\n",
      "training loss 138.74454815869817\n",
      "epoch 21\n",
      "training loss 128.340294130243\n",
      "epoch 22\n",
      "training loss 115.99295295638784\n",
      "epoch 23\n",
      "training loss 105.41144874368175\n",
      "epoch 24\n",
      "training loss 96.32881713019908\n",
      "epoch 25\n",
      "training loss 84.99657387732982\n",
      "epoch 26\n",
      "training loss 75.8865879572359\n",
      "epoch 27\n",
      "training loss 67.84093890259643\n",
      "epoch 28\n",
      "training loss 59.46862626447405\n",
      "epoch 29\n",
      "training loss 51.58149795325508\n",
      "epoch 30\n",
      "training loss 43.95668051768401\n",
      "epoch 31\n",
      "training loss 37.62283362711295\n",
      "epoch 32\n",
      "training loss 31.092476902563092\n",
      "epoch 33\n",
      "training loss 25.147513370366497\n",
      "epoch 34\n",
      "training loss 20.355738123904427\n",
      "epoch 35\n",
      "training loss 16.485516966282532\n",
      "epoch 36\n",
      "training loss 13.189183814006038\n",
      "epoch 37\n",
      "training loss 10.56466701041944\n",
      "epoch 38\n",
      "training loss 8.53209423636668\n",
      "epoch 39\n",
      "training loss 6.9788370003036455\n",
      "epoch 40\n",
      "training loss 5.777558991194514\n",
      "epoch 41\n",
      "training loss 4.591544677621245\n",
      "epoch 42\n",
      "training loss 3.7364229293724924\n",
      "epoch 43\n",
      "training loss 3.059418060543598\n",
      "epoch 44\n",
      "training loss 2.567154316794842\n",
      "epoch 45\n",
      "training loss 2.080537647424118\n",
      "epoch 46\n",
      "training loss 1.7255167601221844\n",
      "epoch 47\n",
      "training loss 1.4046778927396768\n",
      "epoch 48\n",
      "training loss 1.1765591797458335\n",
      "epoch 49\n",
      "training loss 0.992268216759987\n",
      "epoch 50\n",
      "training loss 0.9337850435159529\n",
      "epoch 51\n",
      "training loss 0.8646469765007275\n",
      "epoch 52\n",
      "training loss 0.8064778371226867\n",
      "epoch 53\n",
      "training loss 0.7568206876621182\n",
      "epoch 54\n",
      "training loss 0.706202771539289\n",
      "epoch 55\n",
      "training loss 0.6605473030597746\n",
      "epoch 56\n",
      "training loss 0.621481796135046\n",
      "epoch 57\n",
      "training loss 0.5788686542492615\n",
      "epoch 58\n",
      "training loss 0.5426694777138608\n",
      "epoch 59\n",
      "training loss 0.5114439790786364\n",
      "epoch 60\n",
      "training loss 0.47859770218059916\n",
      "epoch 61\n",
      "training loss 0.4462045601233777\n",
      "epoch 62\n",
      "training loss 0.42174107184504606\n",
      "epoch 63\n",
      "training loss 0.39644850518506647\n",
      "epoch 64\n",
      "training loss 0.37039261153247804\n",
      "epoch 65\n",
      "training loss 0.34698081751780396\n",
      "epoch 66\n",
      "training loss 0.3271982382740804\n",
      "epoch 67\n",
      "training loss 0.31029672482223297\n",
      "epoch 68\n",
      "training loss 0.29141714026487425\n",
      "epoch 69\n",
      "training loss 0.26954386086196064\n",
      "epoch 70\n",
      "training loss 0.25231999757388124\n",
      "epoch 71\n",
      "training loss 0.23762585765052333\n",
      "epoch 72\n",
      "training loss 0.22410380883318357\n",
      "epoch 73\n",
      "training loss 0.21054067719741118\n",
      "epoch 74\n",
      "training loss 0.19980457741861954\n",
      "epoch 75\n",
      "training loss 0.1866228007303634\n",
      "epoch 76\n",
      "training loss 0.1761637655468834\n",
      "epoch 77\n",
      "training loss 0.16690274353021295\n",
      "epoch 78\n",
      "training loss 0.1568182076517479\n",
      "epoch 79\n",
      "training loss 0.14945684668878512\n",
      "epoch 80\n",
      "training loss 0.1389695142025078\n",
      "epoch 81\n",
      "training loss 0.13127924440923733\n",
      "epoch 82\n",
      "training loss 0.1242747122596282\n",
      "epoch 83\n",
      "training loss 0.11744207716369993\n",
      "epoch 84\n",
      "training loss 0.11179529816847758\n",
      "epoch 85\n",
      "training loss 0.10641366750441787\n",
      "epoch 86\n",
      "training loss 0.10171054687736703\n",
      "epoch 87\n",
      "training loss 0.09704213552230932\n",
      "epoch 88\n",
      "training loss 0.09202656938877739\n",
      "epoch 89\n",
      "training loss 0.08820830874314195\n",
      "epoch 90\n",
      "training loss 0.08398579716310811\n",
      "epoch 91\n",
      "training loss 0.07975927762847607\n",
      "epoch 92\n",
      "training loss 0.07615746472275346\n",
      "epoch 93\n",
      "training loss 0.07259936506796476\n",
      "epoch 94\n",
      "training loss 0.06984518449396349\n",
      "epoch 95\n",
      "training loss 0.06700617596858348\n",
      "epoch 96\n",
      "training loss 0.06424551552515567\n",
      "epoch 97\n",
      "training loss 0.062081691452467815\n",
      "epoch 98\n",
      "training loss 0.05904554419531772\n",
      "epoch 99\n",
      "training loss 0.05743998360541955\n",
      "epoch 100\n",
      "training loss 0.05669066677617705\n",
      "epoch 101\n",
      "training loss 0.056040724412214506\n",
      "epoch 102\n",
      "training loss 0.05547849017085927\n",
      "epoch 103\n",
      "training loss 0.05493237991515876\n",
      "epoch 104\n",
      "training loss 0.05447676007175429\n",
      "epoch 105\n",
      "training loss 0.05399968540778579\n",
      "epoch 106\n",
      "training loss 0.05348019272133937\n",
      "epoch 107\n",
      "training loss 0.05306635428166878\n",
      "epoch 108\n",
      "training loss 0.052603734411803604\n",
      "epoch 109\n",
      "training loss 0.052116688570229774\n",
      "epoch 110\n",
      "training loss 0.05170006026472544\n",
      "epoch 111\n",
      "training loss 0.05123914654174335\n",
      "epoch 112\n",
      "training loss 0.050814232552577866\n",
      "epoch 113\n",
      "training loss 0.050420436013866955\n",
      "epoch 114\n",
      "training loss 0.05014353382135313\n",
      "epoch 115\n",
      "training loss 0.049539254723835247\n",
      "epoch 116\n",
      "training loss 0.04914241238133617\n",
      "epoch 117\n",
      "training loss 0.04873068139416598\n",
      "epoch 118\n",
      "training loss 0.048301682364531084\n",
      "epoch 119\n",
      "training loss 0.0479208013898157\n",
      "epoch 120\n",
      "training loss 0.047538850370764246\n",
      "epoch 121\n",
      "training loss 0.04715213404139816\n",
      "epoch 122\n",
      "training loss 0.04677595438234246\n",
      "epoch 123\n",
      "training loss 0.04639519145311179\n",
      "epoch 124\n",
      "training loss 0.046020801008531655\n",
      "epoch 125\n",
      "training loss 0.045623791480407426\n",
      "epoch 126\n",
      "training loss 0.04526888630670992\n",
      "epoch 127\n",
      "training loss 0.044956383076666086\n",
      "epoch 128\n",
      "training loss 0.04457598378726755\n",
      "epoch 129\n",
      "training loss 0.04423082322497911\n",
      "epoch 130\n",
      "training loss 0.04388112206153144\n",
      "epoch 131\n",
      "training loss 0.04359968441824798\n",
      "epoch 132\n",
      "training loss 0.043297280358623326\n",
      "epoch 133\n",
      "training loss 0.042983520914522046\n",
      "epoch 134\n",
      "training loss 0.04272593673794894\n",
      "epoch 135\n",
      "training loss 0.04242108018338218\n",
      "epoch 136\n",
      "training loss 0.0421400931064015\n",
      "epoch 137\n",
      "training loss 0.04185833946947733\n",
      "epoch 138\n",
      "training loss 0.041588002027973504\n",
      "epoch 139\n",
      "training loss 0.04135905342885969\n",
      "epoch 140\n",
      "training loss 0.041073950320932084\n",
      "epoch 141\n",
      "training loss 0.04082553561836527\n",
      "epoch 142\n",
      "training loss 0.04053875012468792\n",
      "epoch 143\n",
      "training loss 0.040320493548137167\n",
      "epoch 144\n",
      "training loss 0.04004947170998144\n",
      "epoch 145\n",
      "training loss 0.03979765190733662\n",
      "epoch 146\n",
      "training loss 0.03956610855318724\n",
      "epoch 147\n",
      "training loss 0.039333414763781445\n",
      "epoch 148\n",
      "training loss 0.03905808417659716\n",
      "epoch 149\n",
      "training loss 0.0388521363444825\n",
      "epoch 150\n",
      "training loss 0.038819160611856376\n",
      "epoch 151\n",
      "training loss 0.038789191966165704\n",
      "epoch 152\n",
      "training loss 0.038762012874428084\n",
      "epoch 153\n",
      "training loss 0.03872971789349876\n",
      "epoch 154\n",
      "training loss 0.03870086338013782\n",
      "epoch 155\n",
      "training loss 0.03867268652462778\n",
      "epoch 156\n",
      "training loss 0.03864448039288791\n",
      "epoch 157\n",
      "training loss 0.03861751291313479\n",
      "epoch 158\n",
      "training loss 0.03859290120432049\n",
      "epoch 159\n",
      "training loss 0.038560954540702304\n",
      "epoch 160\n",
      "training loss 0.0385368076022095\n",
      "epoch 161\n",
      "training loss 0.038504573492435155\n",
      "epoch 162\n",
      "training loss 0.038482188448846544\n",
      "epoch 163\n",
      "training loss 0.03845020453948638\n",
      "epoch 164\n",
      "training loss 0.038421569715835116\n",
      "epoch 165\n",
      "training loss 0.038397537042925235\n",
      "epoch 166\n",
      "training loss 0.038371320259628604\n",
      "epoch 167\n",
      "training loss 0.0383416900299104\n",
      "epoch 168\n",
      "training loss 0.038312874035228345\n",
      "epoch 169\n",
      "training loss 0.03828578081290159\n",
      "epoch 170\n",
      "training loss 0.03825856602366425\n",
      "epoch 171\n",
      "training loss 0.0382298831354537\n",
      "epoch 172\n",
      "training loss 0.03820487965223579\n",
      "epoch 173\n",
      "training loss 0.03817625681667507\n",
      "epoch 174\n",
      "training loss 0.03815212113120118\n",
      "epoch 175\n",
      "training loss 0.03812458953437211\n",
      "epoch 176\n",
      "training loss 0.038098374394528914\n",
      "epoch 177\n",
      "training loss 0.038070274759852245\n",
      "epoch 178\n",
      "training loss 0.03804133547204785\n",
      "epoch 179\n",
      "training loss 0.03801687327216404\n",
      "epoch 180\n",
      "training loss 0.03798919639574088\n",
      "epoch 181\n",
      "training loss 0.03796153032486715\n",
      "epoch 182\n",
      "training loss 0.03793617946554818\n",
      "epoch 183\n",
      "training loss 0.03790808929832757\n",
      "epoch 184\n",
      "training loss 0.037881367636695876\n",
      "epoch 185\n",
      "training loss 0.037854058140149104\n",
      "epoch 186\n",
      "training loss 0.03782792423544632\n",
      "epoch 187\n",
      "training loss 0.03780026013551736\n",
      "epoch 188\n",
      "training loss 0.03777524403478131\n",
      "epoch 189\n",
      "training loss 0.03774585823071056\n",
      "epoch 190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss 0.037726889583348806\n",
      "epoch 191\n",
      "training loss 0.03769299549867437\n",
      "epoch 192\n",
      "training loss 0.03767229184715161\n",
      "epoch 193\n",
      "training loss 0.03764361834776537\n",
      "epoch 194\n",
      "training loss 0.03761897838000953\n",
      "epoch 195\n",
      "training loss 0.037587171967380026\n",
      "epoch 196\n",
      "training loss 0.03756368200365014\n",
      "epoch 197\n",
      "training loss 0.03753655938535373\n",
      "epoch 198\n",
      "training loss 0.037511009527948946\n",
      "epoch 199\n",
      "training loss 0.03749254194077199\n",
      "epoch 200\n",
      "training loss 0.037491356080015636\n",
      "epoch 201\n",
      "training loss 0.037487406579243134\n",
      "epoch 202\n",
      "training loss 0.03748511563758938\n",
      "epoch 203\n",
      "training loss 0.03748197618347033\n",
      "epoch 204\n",
      "training loss 0.037479458423251955\n",
      "epoch 205\n",
      "training loss 0.03747686478586801\n",
      "epoch 206\n",
      "training loss 0.03747383385920507\n",
      "epoch 207\n",
      "training loss 0.037471137781408564\n",
      "epoch 208\n",
      "training loss 0.03746832150697133\n",
      "epoch 209\n",
      "training loss 0.037466196861121875\n",
      "epoch 210\n",
      "training loss 0.037463041925272125\n",
      "epoch 211\n",
      "training loss 0.037460441551773194\n",
      "epoch 212\n",
      "training loss 0.037457705451470945\n",
      "epoch 213\n",
      "training loss 0.03745574011461847\n",
      "epoch 214\n",
      "training loss 0.0374521548787892\n",
      "epoch 215\n",
      "training loss 0.03744946702996106\n",
      "epoch 216\n",
      "training loss 0.03744672448164688\n",
      "epoch 217\n",
      "training loss 0.037444098347875626\n",
      "epoch 218\n",
      "training loss 0.0374413057646022\n",
      "epoch 219\n",
      "training loss 0.03743845648082742\n",
      "epoch 220\n",
      "training loss 0.03743576824892563\n",
      "epoch 221\n",
      "training loss 0.03743300277381609\n",
      "epoch 222\n",
      "training loss 0.03743032634995122\n",
      "epoch 223\n",
      "training loss 0.03742833092999898\n",
      "epoch 224\n",
      "training loss 0.03742529338462747\n",
      "epoch 225\n",
      "training loss 0.03742241585333259\n",
      "epoch 226\n",
      "training loss 0.03741992116702491\n",
      "epoch 227\n",
      "training loss 0.037417208942350434\n",
      "epoch 228\n",
      "training loss 0.03741438204549777\n",
      "epoch 229\n",
      "training loss 0.03741145891824214\n",
      "epoch 230\n",
      "training loss 0.03740872482173701\n",
      "epoch 231\n",
      "training loss 0.037406241694077705\n",
      "epoch 232\n",
      "training loss 0.03740328652878863\n",
      "epoch 233\n",
      "training loss 0.03740083679236695\n",
      "epoch 234\n",
      "training loss 0.03739797377116166\n",
      "epoch 235\n",
      "training loss 0.037395252618233774\n",
      "epoch 236\n",
      "training loss 0.0373928130922912\n",
      "epoch 237\n",
      "training loss 0.03738998385586046\n",
      "epoch 238\n",
      "training loss 0.03738705561209926\n",
      "epoch 239\n",
      "training loss 0.03738445012403606\n",
      "epoch 240\n",
      "training loss 0.03738188686993786\n",
      "epoch 241\n",
      "training loss 0.03737923539583064\n",
      "epoch 242\n",
      "training loss 0.03737625420557327\n",
      "epoch 243\n",
      "training loss 0.03737369688147402\n",
      "epoch 244\n",
      "training loss 0.037371185587648216\n",
      "epoch 245\n",
      "training loss 0.03736835723546252\n",
      "epoch 246\n",
      "training loss 0.03736543492033647\n",
      "epoch 247\n",
      "training loss 0.0373631300594366\n",
      "epoch 248\n",
      "training loss 0.037360085071440494\n",
      "epoch 249\n",
      "training loss 0.03735893128846478\n",
      "epoch 250\n",
      "training loss 0.03735868909482264\n",
      "epoch 251\n",
      "training loss 0.03735843907629085\n",
      "epoch 252\n",
      "training loss 0.03735815232760765\n",
      "epoch 253\n",
      "training loss 0.0373579115276041\n",
      "epoch 254\n",
      "training loss 0.03735762411694346\n",
      "epoch 255\n",
      "training loss 0.037357367469418645\n",
      "epoch 256\n",
      "training loss 0.03735708623598113\n",
      "epoch 257\n",
      "training loss 0.037356806315332655\n",
      "epoch 258\n",
      "training loss 0.03735654218222764\n",
      "epoch 259\n",
      "training loss 0.03735625721995916\n",
      "epoch 260\n",
      "training loss 0.037356045639980684\n",
      "epoch 261\n",
      "training loss 0.03735573665594976\n",
      "epoch 262\n",
      "training loss 0.03735545407410206\n",
      "epoch 263\n",
      "training loss 0.03735518899817532\n",
      "epoch 264\n",
      "training loss 0.03735489923064706\n",
      "epoch 265\n",
      "training loss 0.03735462335267782\n",
      "epoch 266\n",
      "training loss 0.03735440587739027\n",
      "epoch 267\n",
      "training loss 0.03735415125526867\n",
      "epoch 268\n",
      "training loss 0.03735383026734837\n",
      "epoch 269\n",
      "training loss 0.037353574021815036\n",
      "epoch 270\n",
      "training loss 0.03735327294573484\n",
      "epoch 271\n",
      "training loss 0.03735299926571853\n",
      "epoch 272\n",
      "training loss 0.0373527216529259\n",
      "epoch 273\n",
      "training loss 0.037352454528639126\n",
      "epoch 274\n",
      "training loss 0.037352213147023125\n",
      "epoch 275\n",
      "training loss 0.03735190202435921\n",
      "epoch 276\n",
      "training loss 0.037351625426518466\n",
      "epoch 277\n",
      "training loss 0.037351433244554706\n",
      "epoch 278\n",
      "training loss 0.03735112046547526\n",
      "epoch 279\n",
      "training loss 0.037350817412735084\n",
      "epoch 280\n",
      "training loss 0.03735056229441235\n",
      "epoch 281\n",
      "training loss 0.03735028017023292\n",
      "epoch 282\n",
      "training loss 0.03734999277389112\n",
      "epoch 283\n",
      "training loss 0.03734971909923293\n",
      "epoch 284\n",
      "training loss 0.03734944270829103\n",
      "epoch 285\n",
      "training loss 0.037349166395328585\n",
      "epoch 286\n",
      "training loss 0.037348903618269536\n",
      "epoch 287\n",
      "training loss 0.037348642640140775\n",
      "epoch 288\n",
      "training loss 0.037348355052482414\n",
      "epoch 289\n",
      "training loss 0.03734809103771468\n",
      "epoch 290\n",
      "training loss 0.037347806564109826\n",
      "epoch 291\n",
      "training loss 0.03734754417734903\n",
      "epoch 292\n",
      "training loss 0.03734730100572823\n",
      "epoch 293\n",
      "training loss 0.03734703890490392\n",
      "epoch 294\n",
      "training loss 0.037346754782573086\n",
      "epoch 295\n",
      "training loss 0.03734646999394466\n",
      "epoch 296\n",
      "training loss 0.03734620381625978\n",
      "epoch 297\n",
      "training loss 0.03734591470334273\n",
      "epoch 298\n",
      "training loss 0.03734564283962049\n",
      "epoch 299\n",
      "lowest_loss 0.03734564283962049\n",
      "epoch at 299\n",
      "[[29.99999777]\n",
      " [37.99999515]\n",
      " [44.99999365]\n",
      " [53.99998706]\n",
      " [55.99977078]\n",
      " [59.99949505]\n",
      " [62.99964193]\n",
      " [ 1.41126367]\n",
      " [21.9999958 ]\n",
      " [33.99999595]\n",
      " [40.9999957 ]\n",
      " [45.99999492]\n",
      " [50.99999331]\n",
      " [54.99998799]\n",
      " [58.99998718]\n",
      " [61.99897673]\n",
      " [17.99999273]\n",
      " [26.99999545]\n",
      " [34.999997  ]\n",
      " [41.99999419]\n",
      " [47.99999339]\n",
      " [51.99999255]\n",
      " [56.9999894 ]\n",
      " [60.99897704]\n",
      " [13.99999905]\n",
      " [20.99999747]\n",
      " [27.99999587]\n",
      " [32.99999463]\n",
      " [38.99999353]\n",
      " [46.99999264]\n",
      " [49.99999182]\n",
      " [57.99952102]\n",
      " [ 8.99999667]\n",
      " [14.99999782]\n",
      " [19.99999546]\n",
      " [23.99999395]\n",
      " [30.99999566]\n",
      " [39.99999534]\n",
      " [48.99999352]\n",
      " [52.99999039]\n",
      " [ 5.99988396]\n",
      " [ 9.97250496]\n",
      " [12.99999987]\n",
      " [16.9999928 ]\n",
      " [24.99999219]\n",
      " [35.99999207]\n",
      " [42.99999058]\n",
      " [43.99999582]\n",
      " [ 2.99977894]\n",
      " [ 4.99999925]\n",
      " [ 6.99999973]\n",
      " [10.99999699]\n",
      " [15.99998352]\n",
      " [22.99999753]\n",
      " [31.99999385]\n",
      " [36.9999939 ]\n",
      " [ 1.62198709]\n",
      " [ 2.10387127]\n",
      " [ 3.99455753]\n",
      " [ 7.99971096]\n",
      " [11.99999532]\n",
      " [18.99999703]\n",
      " [25.99999505]\n",
      " [28.99999562]]\n",
      "[[29.99999777]\n",
      " [37.99999515]\n",
      " [44.99999365]\n",
      " [53.99998706]\n",
      " [55.99977078]\n",
      " [59.99949505]\n",
      " [62.99964193]\n",
      " [ 1.41126367]\n",
      " [21.9999958 ]\n",
      " [33.99999595]\n",
      " [40.9999957 ]\n",
      " [45.99999492]\n",
      " [50.99999331]\n",
      " [54.99998799]\n",
      " [58.99998718]\n",
      " [61.99897673]\n",
      " [17.99999273]\n",
      " [26.99999545]\n",
      " [34.999997  ]\n",
      " [41.99999419]\n",
      " [47.99999339]\n",
      " [51.99999255]\n",
      " [56.9999894 ]\n",
      " [60.99897704]\n",
      " [13.99999905]\n",
      " [20.99999747]\n",
      " [27.99999587]\n",
      " [32.99999463]\n",
      " [38.99999353]\n",
      " [46.99999264]\n",
      " [49.99999182]\n",
      " [57.99952102]\n",
      " [ 8.99999667]\n",
      " [14.99999782]\n",
      " [19.99999546]\n",
      " [23.99999395]\n",
      " [30.99999566]\n",
      " [39.99999534]\n",
      " [48.99999352]\n",
      " [52.99999039]\n",
      " [ 5.99988396]\n",
      " [ 9.97250496]\n",
      " [12.99999987]\n",
      " [16.9999928 ]\n",
      " [24.99999219]\n",
      " [35.99999207]\n",
      " [42.99999058]\n",
      " [43.99999582]\n",
      " [ 2.99977894]\n",
      " [ 4.99999925]\n",
      " [ 6.99999973]\n",
      " [10.99999699]\n",
      " [15.99998352]\n",
      " [22.99999753]\n",
      " [31.99999385]\n",
      " [36.9999939 ]\n",
      " [ 1.62198709]\n",
      " [ 2.10387127]\n",
      " [ 3.99455753]\n",
      " [ 7.99971096]\n",
      " [11.99999532]\n",
      " [18.99999703]\n",
      " [25.99999505]\n",
      " [28.99999562]]\n",
      "---------\n",
      "→ → → → → → → G \n",
      "→ → → ↑ ↑ ↑ ↑ ↑ \n",
      "→ → → → → → → ↑ \n",
      "→ → ↑ ↑ ↑ ↑ → ↑ \n",
      "→ ↑ ↑ ↑ → → → ↑ \n",
      "→ ↑ ↑ → → → ↑ ↑ \n",
      "↑ ↑ ↑ ↑ ↑ ↑ ↑ ↑ \n",
      "↑ ↑ → → → → ↑ ↑ \n",
      "[30. 38. 45. 54. 56. 60. 63.  1. 22. 34. 41. 46. 51. 55. 59. 62. 18. 27.\n",
      " 35. 42. 48. 52. 57. 61. 14. 21. 28. 33. 39. 47. 50. 58.  9. 15. 20. 24.\n",
      " 31. 40. 49. 53.  6. 10. 13. 17. 25. 36. 43. 44.  3.  5.  7. 11. 16. 23.\n",
      " 32. 37.  2.  2.  4.  8. 12. 19. 26. 29.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize, OneHotEncoder\n",
    "import random\n",
    "def count_parameters(model):\n",
    "    return sum([np.prod(p.size()) for p in model.parameters() if p.requires_grad])\n",
    "X = []\n",
    "X_coor = []\n",
    "for i in range(Terminal.shape[0]):\n",
    "    for j in range(Terminal.shape[1]):\n",
    "        if Terminal[i,j]!=1:\n",
    "            X.append(i*Terminal.shape[1]+j)\n",
    "            X_coor.append([i,j])\n",
    "X = np.array(X)\n",
    "X_coor = np.array(X_coor)\n",
    "y = np.array([V_optimal[x] for x in X])\n",
    "sort_y = np.argsort(y)\n",
    "count = 0\n",
    "for indice in sort_y:\n",
    "    y[indice] = count\n",
    "    count+=1\n",
    "print(y)\n",
    "X = X.reshape(-1,1)\n",
    "in_dim = X.shape[0]*X.shape[1]\n",
    "hid_dim = 8\n",
    "out_dim = 1\n",
    "num_layers = 3\n",
    "lr = 0.001\n",
    "wd = 0.1\n",
    "model = ANN(in_dim, hid_dim, out_dim, num_layers)\n",
    "model = model.double()\n",
    "print(f'# params: {count_parameters(model)}')\n",
    "# target_model  = copy.deepcopy(model)\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create a mapping from original index to compressed version\n",
    "onehot_encoder = OneHotEncoder(categories='auto').fit(X)\n",
    "X = onehot_encoder.transform(X).toarray().astype(int)\n",
    "# print(X.shape)\n",
    "print(\"X\",X)\n",
    "# print(y)\n",
    "x_train = th.from_numpy(X).double()\n",
    "y_train = th.from_numpy(y).double()\n",
    "# x_train = th.from_numpy(X_coor).double()\n",
    "# x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "# print(x_train.shape)\n",
    "# x_train = th.from_numpy(x_train).double()\n",
    "# x_val = th.from_numpy(x_val).double()\n",
    "# y_train = th.from_numpy(y_train).double()\n",
    "# y_train = y_train.reshape((y_train.shape[0],1))\n",
    "# y_val = th.from_numpy(y_val).double()\n",
    "# y_val = y_val.reshape((y_val.shape[0],1))\n",
    "# x_train = Variable(x_train)\n",
    "# y_trian = Variable(y_train)\n",
    "\n",
    "epochs = 300\n",
    "early_stop = 0\n",
    "lowest_loss = 100\n",
    "epoch = 0\n",
    "for e in range(epochs):\n",
    "    index_list = th.randperm(x_train.shape[0])\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    if e %50 ==0 and e!=0:\n",
    "        lr = lr/10\n",
    "        optimizer = th.optim.Adam(model.parameters(), lr=lr)\n",
    "    for i in index_list:\n",
    "        x = x_train[i]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output,y_train[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum+=loss.item()\n",
    "#     model.eval()\n",
    "#     output = model(x_val)\n",
    "#     loss_cur =criterion(output,y_val)\n",
    "#     if e!=0 and loss_cur>=loss_pre:\n",
    "#         early_stop+=1\n",
    "#         print(\"epoch\",e)\n",
    "#         print(\"early stop\")\n",
    "#         if early_stop>=10:\n",
    "#             break\n",
    "#     loss_pre = loss_cur\n",
    "#     print(\"validation loss\",loss_cur)\n",
    "    if lowest_loss>=loss_sum/in_dim:\n",
    "        lowest_loss = loss_sum/in_dim\n",
    "        epoch = e\n",
    "    print(\"training loss\",loss_sum/in_dim)\n",
    "    print(\"epoch\",e)\n",
    "print(\"lowest_loss\",lowest_loss)\n",
    "print(\"epoch at\",epoch)\n",
    "# model.eval()\n",
    "# output = model(x_test)\n",
    "# loss = criterion(output,y_test)\n",
    "# print(\"test loss\",loss)\n",
    "V_predict = model(th.from_numpy(X).double())\n",
    "V_predict = V_predict.detach().cpu().numpy()\n",
    "print(V_predict)\n",
    "y = np.array([V_optimal[x] for x in X])\n",
    "V_final = []\n",
    "count = 0\n",
    "for i in range(Terminal.shape[0]):\n",
    "    for j in range(Terminal.shape[1]):\n",
    "        if Terminal[i,j]!=1:\n",
    "            V_final.append(V_predict[count])\n",
    "            count+=1\n",
    "        else:\n",
    "            V_final.append(-10000)\n",
    "V_final = np.array(V_final)\n",
    "print(V_final)\n",
    "controller.eval_mode(V_final)\n",
    "np.set_printoptions(precision=0)\n",
    "print(V_final.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98610912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
